{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading the data \n",
    "original_df = pd.read_csv('anime.csv')\n",
    "original_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime=original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['episodes', 'status', 'rank','aired','duration','premiered',]\n",
    "anime.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e5eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(input_string):\n",
    "    # Split the input string by spaces and join the words to form a single word\n",
    "    single_word = \"\".join(input_string.split())\n",
    "    return single_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b99cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=anime['title'].apply(remove_spaces)\n",
    "\n",
    "anime['theme']=anime['theme'].apply(remove_spaces)\n",
    "\n",
    "anime['studios']=anime['studios'].apply(remove_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646aca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_commas_add_spaces(text):\n",
    "    return text.replace(',', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da61383",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['genres']=anime['genres'].apply(remove_commas_add_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(text, words_to_remove):\n",
    "    for word in words_to_remove:\n",
    "        text = text.replace(word, '')\n",
    "    return text\n",
    "\n",
    "words_to_remove = ['\\n\\r\\n[Written by MAL Rewrite]','\\n\\r\\n']\n",
    "\n",
    "anime['synopsis'] = anime['synopsis'].apply(lambda x: remove_words(x, words_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Step 1: Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Step 2: Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 3: Remove special characters (non-alphanumeric except whitespace)\n",
    "    tokens = [re.sub(r'[^a-zA-Z\\s]', '', token) for token in tokens]\n",
    "    \n",
    "    # Step 4: Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Step 5: Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into a preprocessed text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['synopsis'] = anime['synopsis'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6985a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['tags']=title+\" \"+anime['theme']+\" \"+anime['demographic']+\" \"+anime['genres']+\" \"+anime['type']+\" \"+anime['synopsis']+\" \"+anime['studios']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb232e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['tags'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0a6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['tags'] = anime['tags'].apply(lambda x:x.replace('Unknown ', ''))\n",
    "#remove double space\n",
    "anime['tags'] = anime['tags'].apply(lambda x: ' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502841cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['tags'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(max_features=10000,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef17a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = cv.fit_transform(anime['tags']).toarray()\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vector)\n",
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b209cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime[anime['title'] == 'Jujutsu Kaisen'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3661d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_recommendation(anime_title):\n",
    "    index = anime[anime['title'] == anime_title].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "\n",
    "    print(\"Content-Based Recommendation \\n\")\n",
    "    for i, (anime_index, similarity_score) in zip(range(0, 10), distances[1:11]):\n",
    "        recommended_anime_title = anime.iloc[anime_index].title\n",
    "        print(f\"{i+1}. {recommended_anime_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eefe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_recommendation('Fullmetal Alchemist: Brotherhood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebab72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=original_df.copy()\n",
    "new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675be45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "numerical_columns = ['score', 'members']\n",
    "\n",
    "# Remove commas from numerical columns and scale using MinMaxScaler\n",
    "new[numerical_columns] = new[numerical_columns].replace({',': ''}, regex=True)\n",
    "scaler = MinMaxScaler()\n",
    "new[numerical_columns] = scaler.fit_transform(new[numerical_columns])\n",
    "\n",
    "anime_rating = pd.concat([new['title'],new[numerical_columns]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54456f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_rating.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ed63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\n",
    "    'score': 'ratings_scores',\n",
    "    'members': 'popularity_members'\n",
    "}\n",
    "\n",
    "anime_rating.rename(columns=new_column_names, inplace=True)\n",
    "anime_rating['average_ratings']=(.85*anime_rating['ratings_scores'])+(.15*anime_rating['popularity_members'])\n",
    "anime_rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468264ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = anime_rating.sort_values(by='average_ratings', ascending=False)\n",
    "sorted_df.iloc[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_recommendation(anime_title):\n",
    "    print(\"Hybrid Recommendation - \",anime_title,)\n",
    "    index = anime[anime['title'] == anime_title].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    # Initialize lists to store the hybrid scores and anime indices for the top similar anime\n",
    "    hybrid_scores = []\n",
    "    similar_anime_indices = []\n",
    "\n",
    "    param=100;\n",
    "    for i, dist in distances[1:(len(distances)//param)]:  # Consider all similar anime\n",
    "        # Get the title of the similar anime\n",
    "        similar_anime_title = anime.iloc[i].title\n",
    "        # Find the row in anime_rating dataframe that corresponds to the similar anime\n",
    "        similar_anime_row = anime_rating [anime_rating['title'] == similar_anime_title]\n",
    "\n",
    "        # Check if the similar anime has a rating score\n",
    "        if not pd.isnull(similar_anime_row['average_ratings'].values[0]):\n",
    "            # Calculate the hybrid score using the given formula\n",
    "            hybrid_score = dist * 0.65 + similar_anime_row['average_ratings'].values[0] * 0.35\n",
    "            hybrid_scores.append((similar_anime_title, hybrid_score))\n",
    "            similar_anime_indices.append(i)\n",
    "\n",
    "    # Sort the hybrid scores in descending order\n",
    "    hybrid_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the top 10 recommended anime with their titles and hybrid scores\n",
    "    print(\"Top 10 Recommended Anime:\\n\")\n",
    "    for i, (anime_title, hybrid_score) in zip(range(1, 11), hybrid_scores):\n",
    "        print(f\"{i}. {anime_title} - (Hybrid Score: {hybrid_score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c870e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('Chainsaw Man')\n",
    "print(\"\\n\")\n",
    "content_recommendation('Chainsaw Man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('Death Note')\n",
    "print(\"\\n\")\n",
    "content_recommendation('Death Note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation(\"Vivy: Fluorite Eye's Song\")\n",
    "print(\"\\n\")\n",
    "content_recommendation(\"Vivy: Fluorite Eye's Song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('Dr. Stone')\n",
    "print(\"\\n\")\n",
    "content_recommendation('Dr. Stone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('Tokyo Ghoul')\n",
    "print(\"\\n\")\n",
    "content_recommendation('Tokyo Ghoul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7fe2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('One Punch Man')\n",
    "print(\"\\n\")\n",
    "content_recommendation('One Punch Man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('Spy x Family')\n",
    "print(\"\\n\")\n",
    "content_recommendation('Spy x Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1479f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_recommendation('86')\n",
    "print(\"\\n\")\n",
    "content_recommendation('86')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fa3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_list = [\n",
    "    '\"Oshi no Ko\"',\n",
    "    \"Charlotte\",\n",
    "    \"Jujutsu Kaisen\" ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for anime_title in anime_list:\n",
    "    # Check if the anime title exists\n",
    "    if anime[anime['title'] == anime_title].empty:\n",
    "        print(f\"{anime_title} not found in the anime dataset.\\n\")\n",
    "    else:\n",
    "        print(f\"Recommendations for {anime_title}:\\n\")\n",
    "        Hybrid_recommendation(anime_title)\n",
    "        print(\"\\n\")\n",
    "        content_recommendation(anime_title)\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f85799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a6e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
